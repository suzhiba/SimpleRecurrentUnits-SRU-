data_train
===================
训练的代码，包括数据载入函数，训练文件和模型定义文件，保存的每一个epoch训练出来的trainer文件，以及从trainer文件提取模型model文件的代码。

文件结构
---------------------
1. model_*.py   
模型定义文件，里面定义了模型结构，loss和学习方法。
2. train_*.py   
训练文件，规定了数据来源，训练和保存的方式。
3. data_provider*.py   
载入数据的函数。
4. extract_model*.py   
从trainer提取model的代码。

data_provider*.py
------------------------
此类程序负责在train*函数执行时的训练和测试中，将数据一个batch一个batch从数据文件夹中取出来。

其中data_provider_loss_weight*.py是传统data_provider的优化，在传回batch数据的同时，计算并传回这个batch中每个数据的权重系数，这样在训练计算loss时，不同的数据可以有不同的loss权重，从而使模型更多的关注某些方面。

例如，在声学模型的训练中，为了加大声音的音调起伏，对每个句训练音频进行了计算，欺负较大的音频赋予了更大的权重，这样在模型训练的时候，就可以更多的从音调起伏大的音频中学习。在时长模型中，由于韵母时长准确率比声母时长准确率更能改变听觉体验，我对声母和韵母也赋予了不同的权重，让模型更加关注韵母。

model*.py
----------------------
模型定义文件，定义了模型的结构、大小和loss的计算方式

由于不同的模型定义文件结构类似，以model_lf0_weight_sgd.py为例。

1. 第14行定义了权重输入参数，用于在计算loss时加权。
2. 第15行定义了说话人的ivector，用于在联合训练和合成时区分输入的说话人。
3. 第21行定义了loss。
4. 第26和27行设置了学习方法。
5. create_parameters()函数定义了模型结构。其中self.dnn_three函数定义了全连接层的层数和神经元数量。修改层数直接加/删Dense函数数量，而Dense函数的第一个参数就是该层的神经元数量。
6. sru的层数和神经元数量的修改相较于全连接层略微复杂。修改层数和神经元数量不能单单修改此处的数值。后面的bsru_layer的数值也需要相应的修改。同时在model()函数中，要相应的增/删

7. 第117行的gen_loss2()函数中定义了loss函数，此处除了带权重的l2 loss外，又加了10倍的181-183维的loss,含义是基频lf0及其一二阶导数。

train*.py
------------------------
规定训练数据、训练方法和模型存放位置，是训练框架的主函数。

由于不同的训练文件结构类似，以train_24k_abc_weight_sgd.py为例。

1. 第3-4行的引用一定要引用对相应的data_provider和model文件。
2. 第10行指定使用的gpu
3. 第17-21行指定了训练和测试数据的信息，包括(list索引文件，输入维度，输出维度，输入的文件夹，输出的文件夹，训练数量，batch_size, index)
4. 第23行的学习率
5. 第24行的输入输出和momenm的大小。
6. 第28行的epoch大小
7. 第32-36行的载入模型（optional）
8. 第44行规定了log文件的名称
9. 第69、70、81、87行分别调用了data_provider的载入batch函数
10. 第72、83、89行分别执行了训练和测试并返回了loss。
11. 第101和110行分别存储和载入trainer，注意trainer的位置。
12. 第106、107、111、112四行实现了梯度衰减

extract_model*.py
---------------------------
用于从训练得到的trainer文件提取出工程框架上使用的模型model文件。

以extract_model_emo_lf0.py为例
1. 第4行指定model定义文件，要和训练的时候的是一个文件。
2. 第6行指定gpu
3. 第10行指定输入维度、输出维度、学习率和动量大小。
4. 第14行指定要提取的trainer的路径
5. 第18行指定说话人的index：第一位是汇听，第二位是小宇宙，第三位是智娃。
6. 第19行指定输入维度
7. 第23行指定model保存的路径。
